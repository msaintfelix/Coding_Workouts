{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.4.1'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load the Fashion MNIST dataset from Keras:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_mnist = keras.datasets.fashion_mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train_full, y_train_full), (X_test, y_test) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our training set consists of 60000 greyscale images (each pixel is an integer that ranges from 0 to 255), size 28x28."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(60000,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dtype('uint8')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(X_train_full.shape)\n",
    "print(y_train_full.shape)\n",
    "X_train_full.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our test set consists of 10000 greyscale images (each pixel is an integer that ranges from 0 to 255), size 28x28."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 28, 28)\n",
      "(10000,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dtype('uint8')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(X_test.shape)\n",
    "print(y_test.shape)\n",
    "X_test.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a best practice, it is important to create a validation set (we already have a training set and a test set). Also we are going to scale the input features (each pixel divided by 255.0) in order to use gradient descent properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid, X_train = X_train_full[:5000]/255.0, X_train_full[5000:]/255.0\n",
    "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]\n",
    "X_test = X_test/255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's visualize one example of the training set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fb8591a6a90>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAP4ElEQVR4nO3db4xUZZbH8d8R/wFiFGmRgBFX8Q9uwDGFmEBG1DhBX4hjdB1jJmhMGI0kYzKJGjdmTHwhMY7jQlYjs5pB4zJOwvjnhdkdYiYS30wslAVcsqIIChK6EQw9giL02RddTHqw7/M0davqFp7vJ+lUd51+6h7L/nGr6rn3PubuAvDDd0LVDQDoDMIOBEHYgSAIOxAEYQeCOLGTG5swYYJPnTq1k5sEQtm6dat2795tw9VKhd3M5kv6N0mjJP2Huy9J/f7UqVNVr9fLbBJAQq1WK6w1/TLezEZJ+ndJN0iaLukOM5ve7OMBaK8y79mvlPSxu29x94OS/iBpQWvaAtBqZcI+WdLnQ37e3rjvH5jZIjOrm1m9r6+vxOYAlFEm7MN9CPC9Y2/dfbm719y91tPTU2JzAMooE/btks4d8vMUSV+UawdAu5QJ+3uSppnZ+WZ2sqSfSXqzNW0BaLWmp97c/ZCZLZb03xqcenvR3T9sWWcAWqrUPLu7vyXprRb1AqCNOFwWCIKwA0EQdiAIwg4EQdiBIAg7EARhB4Ig7EAQhB0IgrADQRB2IAjCDgRB2IEgCDsQBGEHgiDsQBCEHQiCsANBEHYgCMIOBEHYgSAIOxAEYQeCIOxAEIQdCIKwA0EQdiAIwg4EQdiBIEqt4orj3+HDh0vVR40aVap+vFq2bFmyPm7cuGT9rrvuKqwNDAwkx55wQnP76FJhN7OtkvolHZZ0yN1rZR4PQPu0Ys9+jbvvbsHjAGgj3rMDQZQNu0v6s5mtNbNFw/2CmS0ys7qZ1fv6+kpuDkCzyoZ9jrtfIekGSfeb2Y+P/gV3X+7uNXev9fT0lNwcgGaVCru7f9G47ZX0mqQrW9EUgNZrOuxmNtbMxh35XtJPJG1sVWMAWqvMp/ETJb1mZkce5z/d/b9a0hU6psp58kOHDpXaduNvry22bNmSrD/33HPJem4u/KabbiqsjR8/Pjk2d+xDkabD7u5bJM1sdjyAzmLqDQiCsANBEHYgCMIOBEHYgSA4xfUHIDWFdeKJ6f/Fn376abK+Zs2aZH3hwoXJekqutyrl/rv27NmTrN99993Jemp6LXeKa7PToezZgSAIOxAEYQeCIOxAEIQdCIKwA0EQdiCI7p3oxN+5e7Je5jTURx99NFlfu3Ztsv7qq68m67fcckthbe7cucmxl1xySbJexqxZs5L17du3J+tXXHFFsv7EE08cc0/txp4dCIKwA0EQdiAIwg4EQdiBIAg7EARhB4Jgnv04kJtnT122uLe3Nzl2ypQpyfro0aOT9dwll5966qnC2sqVK5NjTzvttGT9kUceSdZXrVpVWNu1a1dybG7J5aVLlybrObnLaLcDe3YgCMIOBEHYgSAIOxAEYQeCIOxAEIQdCIJ59uNAbvnflLPPPjtZX7JkSdOPLUk7duxI1lPXV88dPzBzZnqR4P7+/mR97969hbXvvvsuOfbaa69N1i+88MJkPSf1337SSSeVeuwi2b8iM3vRzHrNbOOQ+8ab2Woz29y4PbMt3QFomZHsMn4vaf5R9z0s6W13nybp7cbPALpYNuzuvkbS0a/FFkha0fh+haSbW9sWgFZr9s3gRHffKUmN28I3hma2yMzqZlbv6+trcnMAymr7p/Huvtzda+5e6+npaffmABRoNuy7zGySJDVu06dWAahcs2F/U9KRNW0XSnqjNe0AaJfsPLuZrZQ0T9IEM9su6deSlkj6o5ndI+kzSbe1s0m0T26u28yS9cmTJ5eqp+R6u/7665P1b775prB2yimnJMc+/vjjyXpZqbn03PEDqWMXDh48WFjLht3d7ygoXZcbC6B7cLgsEARhB4Ig7EAQhB0IgrADQXCK6w9cbvqq7PiBgYGmH7vMUtOS9O677ybrqctkb9u2LTk2dRlqSXrggQeS9Q0bNiTry5cvL6ytXr06Ofb2228vrO3evbuwxp4dCIKwA0EQdiAIwg4EQdiBIAg7EARhB4Jgnv0HLneKalm5ufLDhw83/dgbN25M1nOXyR4zZkxhbfbs2cmx+/btS9YvuuiiZH3z5s3JeurU3xNPTMfy3nvvLay9/vrrhTX27EAQhB0IgrADQRB2IAjCDgRB2IEgCDsQBPPsHVD2cs3HszL/bbnloHPLLqcuJZ2bR3/yySeT9bFjxybrueWmU3JLdE+cOLGwlrpENXt2IAjCDgRB2IEgCDsQBGEHgiDsQBCEHQiiq+bZq5yPzl3/PDWnm1v+94c8j56TmzNOWbZsWbL+7bffJuuzZs0qrE2dOjU59uWXX07WL7vssmT9yy+/TNZTf08HDhxIjm32Oc2OMrMXzazXzDYOue8xM9thZusaXzc2tXUAHTOSfyJ+L2n+MPf/1t0vb3y91dq2ALRaNuzuvkbSng70AqCNynxAt9jM1jde5p9Z9EtmtsjM6mZW7+vrK7E5AGU0G/bnJF0g6XJJOyX9pugX3X25u9fcvdbT09Pk5gCU1VTY3X2Xux929wFJv5N0ZWvbAtBqTYXdzCYN+fGnktLX/AVQuew8u5mtlDRP0gQz2y7p15LmmdnlklzSVkm/aEUzZebZc2Nz1y/PXas7N5d+vMo9L7nnNfe8ff3114W1uXPnNj1Wkh588MFk/aGHHiqsrVmzJjl26dKlyXp/f3+ynrue/v79+wtr7Xq7mw27u98xzN0vtKEXAG3E4bJAEIQdCIKwA0EQdiAIwg4E0VWnuJY5HTJ3Gmluiih12WFJqtfrhbXFixcnx7700kvJ+owZM5L13CWTU5cPzslNvZ188snJ+tatW5P1a665prB21VVXJce+8soryXqZv5fTTz+96bGSdPDgwWQ997ymxo8bN66pnnLYswNBEHYgCMIOBEHYgSAIOxAEYQeCIOxAEB2fZ0/NP+YuDTxmzJjC2qFDh5Jjr7vuumQ9twTv3r17C2u5Of4PPvggWc/Ns5eZR8/JzaN/9tlnyXrqcs2SdOeddxbWnnnmmeTYdrrgggtKjc/Ns+eO60hJLclcBnt2IAjCDgRB2IEgCDsQBGEHgiDsQBCEHQii4/PsqUvspubRc3LzmuPHj0/Wt23blqyfddZZx9zTEffdd1+yvnDhwqYfu6yvvvoqWZ8zZ06yfttttyXrVc6lp+TOGb/00ktLPX7u7zF1bMY555xTattF2LMDQRB2IAjCDgRB2IEgCDsQBGEHgiDsQBAdnWffu3evVq1aVVh//vnnk+PPP//8wtq0adOSY3PzqrmliVPnL+fON585c2ay3tfXl6yXWcI3dy79ggULkvXcssrPPvvsMfd0RNnr4ZdZ4jtn9OjRyXpuOemBgYFkPXfthnbI7tnN7Fwz+4uZbTKzD83sl437x5vZajPb3Lg9s/3tAmjWSF7GH5L0K3e/VNJVku43s+mSHpb0trtPk/R242cAXSobdnff6e7vN77vl7RJ0mRJCyStaPzaCkk3t6lHAC1wTB/QmdlUST+S9FdJE919pzT4D4KkswvGLDKzupnV9+3bV7JdAM0acdjN7DRJqyQ94O4jTq27L3f3mrvXyi6mB6B5Iwq7mZ2kwaC/4u5/aty9y8wmNeqTJPW2p0UArZCderPB+YsXJG1y96eHlN6UtFDSksbtG7nHOvXUU3XxxRcX1idMmJAcv27dusLaO++8kxybuyTyeeedl6zv378/WU/JTbPMnz8/Wb/66quT9ZUrVxbWzjjjjOTYW2+9NVl/+umnk/Wc1BRUOy+RXdaOHTuS9dzzmrtEd+pVbrsuJT2SefY5kn4uaYOZrWvc94gGQ/5HM7tH0meS0ic2A6hUNuzu/q6koqMT0isvAOgaHC4LBEHYgSAIOxAEYQeCIOxAEJY7TbCVarWa1+v1jm1vqP7+/mT9888/T9Z7e4uPGfroo4+SY3Nztp988kmynlseePbs2YW11JLJUvsuW3y8W79+fbKeO3ZiypQpyfqBAwcKa6lTuaX0qbu1Wk31en3YX2DPDgRB2IEgCDsQBGEHgiDsQBCEHQiCsANBdHzJ5qrkLiU9ffr0puvz5s1rpiV0sRkzZlTdQsuxZweCIOxAEIQdCIKwA0EQdiAIwg4EQdiBIAg7EARhB4Ig7EAQhB0IgrADQRB2IAjCDgRB2IEgsmE3s3PN7C9mtsnMPjSzXzbuf8zMdpjZusbXje1vF0CzRnLxikOSfuXu75vZOElrzWx1o/Zbd3+qfe0BaJWRrM++U9LOxvf9ZrZJ0uR2NwagtY7pPbuZTZX0I0l/bdy12MzWm9mLZnZmwZhFZlY3s3pfX1+5bgE0bcRhN7PTJK2S9IC775P0nKQLJF2uwT3/b4Yb5+7L3b3m7rWenp7yHQNoyojCbmYnaTDor7j7nyTJ3Xe5+2F3H5D0O0lXtq9NAGWN5NN4k/SCpE3u/vSQ+ycN+bWfStrY+vYAtMpIPo2fI+nnkjaY2brGfY9IusPMLpfkkrZK+kUb+gPQIiP5NP5dScOt9/xW69sB0C4cQQcEQdiBIAg7EARhB4Ig7EAQhB0IgrADQRB2IAjCDgRB2IEgCDsQBGEHgiDsQBCEHQjC3L1zGzPrk7RtyF0TJO3uWAPHplt769a+JHprVit7O8/dh73+W0fD/r2Nm9XdvVZZAwnd2lu39iXRW7M61Rsv44EgCDsQRNVhX17x9lO6tbdu7Uuit2Z1pLdK37MD6Jyq9+wAOoSwA0FUEnYzm29m/2dmH5vZw1X0UMTMtprZhsYy1PWKe3nRzHrNbOOQ+8ab2Woz29y4HXaNvYp664plvBPLjFf63FW9/HnH37Ob2ShJH0m6XtJ2Se9JusPd/7ejjRQws62Sau5e+QEYZvZjSX+T9JK7/3Pjvicl7XH3JY1/KM9094e6pLfHJP2t6mW8G6sVTRq6zLikmyXdpQqfu0Rf/6IOPG9V7NmvlPSxu29x94OS/iBpQQV9dD13XyNpz1F3L5C0ovH9Cg3+sXRcQW9dwd13uvv7je/7JR1ZZrzS5y7RV0dUEfbJkj4f8vN2ddd67y7pz2a21swWVd3MMCa6+05p8I9H0tkV93O07DLenXTUMuNd89w1s/x5WVWEfbilpLpp/m+Ou18h6QZJ9zdermJkRrSMd6cMs8x4V2h2+fOyqgj7dknnDvl5iqQvKuhjWO7+ReO2V9Jr6r6lqHcdWUG3cdtbcT9/103LeA+3zLi64LmrcvnzKsL+nqRpZna+mZ0s6WeS3qygj+8xs7GND05kZmMl/UTdtxT1m5IWNr5fKOmNCnv5B92yjHfRMuOq+LmrfPlzd+/4l6QbNfiJ/CeS/rWKHgr6+idJ/9P4+rDq3iSt1ODLuu80+IroHklnSXpb0ubG7fgu6u1lSRskrddgsCZV1NtcDb41XC9pXePrxqqfu0RfHXneOFwWCIIj6IAgCDsQBGEHgiDsQBCEHQiCsANBEHYgiP8HZX/pmnvmxG8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_train[30], cmap='binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's initialize a list of class names for MNIST (details of the dataset available via google):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = [\"T-shirt\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\", \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Boot\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's define our architecture by passing a list of layers to the Sequential model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28,28]),\n",
    "    keras.layers.Dense(300, activation='relu'),\n",
    "    keras.layers.Dense(100, activation='relu'),\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: the Flatten() layer computes X.reshape(-1, 28*28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 300)               235500    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               30100     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 266,610\n",
      "Trainable params: 266,610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List of layers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tensorflow.python.keras.layers.core.Flatten at 0x7fb87a3d5190>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x7fb87a3ee760>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x7fb87a3eea90>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x7fb87a3eedf0>]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compile our model using a multi-label loss function: 'sparse_categorical_crossentropy' (as the classes are not one-hot-encoded). We are using a Stochastic Gradient Descent  with a default learning rate lr=0.01 to optimize 'accuracy' of our model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"sgd\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's train our model on 30 epochs and pass 'validation_data' on which Keras will measure the loss and metrics at the end of each epoch. The model will not train on validation data. This validation set is not affected by optional regularization layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 1.0067 - accuracy: 0.6912 - val_loss: 0.5209 - val_accuracy: 0.8174\n",
      "Epoch 2/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.5015 - accuracy: 0.8251 - val_loss: 0.4461 - val_accuracy: 0.8454\n",
      "Epoch 3/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.4564 - accuracy: 0.8387 - val_loss: 0.4118 - val_accuracy: 0.8598\n",
      "Epoch 4/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.4184 - accuracy: 0.8529 - val_loss: 0.3927 - val_accuracy: 0.8642\n",
      "Epoch 5/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.4000 - accuracy: 0.8607 - val_loss: 0.3830 - val_accuracy: 0.8666\n",
      "Epoch 6/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3817 - accuracy: 0.8640 - val_loss: 0.3607 - val_accuracy: 0.8764\n",
      "Epoch 7/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3674 - accuracy: 0.8673 - val_loss: 0.3702 - val_accuracy: 0.8694\n",
      "Epoch 8/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3549 - accuracy: 0.8741 - val_loss: 0.3535 - val_accuracy: 0.8758\n",
      "Epoch 9/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3414 - accuracy: 0.8781 - val_loss: 0.3672 - val_accuracy: 0.8684\n",
      "Epoch 10/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3318 - accuracy: 0.8810 - val_loss: 0.3489 - val_accuracy: 0.8754\n",
      "Epoch 11/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.3196 - accuracy: 0.8871 - val_loss: 0.3373 - val_accuracy: 0.8802\n",
      "Epoch 12/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3161 - accuracy: 0.8884 - val_loss: 0.3380 - val_accuracy: 0.8794\n",
      "Epoch 13/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3086 - accuracy: 0.8884 - val_loss: 0.3423 - val_accuracy: 0.8770\n",
      "Epoch 14/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3007 - accuracy: 0.8919 - val_loss: 0.3241 - val_accuracy: 0.8812\n",
      "Epoch 15/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2967 - accuracy: 0.8934 - val_loss: 0.3395 - val_accuracy: 0.8792\n",
      "Epoch 16/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2838 - accuracy: 0.8992 - val_loss: 0.3161 - val_accuracy: 0.8886\n",
      "Epoch 17/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2822 - accuracy: 0.8986 - val_loss: 0.3195 - val_accuracy: 0.8832\n",
      "Epoch 18/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2808 - accuracy: 0.9002 - val_loss: 0.3227 - val_accuracy: 0.8812\n",
      "Epoch 19/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2708 - accuracy: 0.9024 - val_loss: 0.3177 - val_accuracy: 0.8852\n",
      "Epoch 20/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2651 - accuracy: 0.9050 - val_loss: 0.3177 - val_accuracy: 0.8842\n",
      "Epoch 21/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2642 - accuracy: 0.9048 - val_loss: 0.3019 - val_accuracy: 0.8926\n",
      "Epoch 22/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2650 - accuracy: 0.9049 - val_loss: 0.3081 - val_accuracy: 0.8886\n",
      "Epoch 23/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2537 - accuracy: 0.9092 - val_loss: 0.2972 - val_accuracy: 0.8920\n",
      "Epoch 24/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2454 - accuracy: 0.9113 - val_loss: 0.3001 - val_accuracy: 0.8904\n",
      "Epoch 25/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2387 - accuracy: 0.9149 - val_loss: 0.3027 - val_accuracy: 0.8910\n",
      "Epoch 26/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2438 - accuracy: 0.9129 - val_loss: 0.2998 - val_accuracy: 0.8930\n",
      "Epoch 27/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2420 - accuracy: 0.9136 - val_loss: 0.2956 - val_accuracy: 0.8918\n",
      "Epoch 28/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2311 - accuracy: 0.9166 - val_loss: 0.3009 - val_accuracy: 0.8898\n",
      "Epoch 29/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2278 - accuracy: 0.9182 - val_loss: 0.3162 - val_accuracy: 0.8902\n",
      "Epoch 30/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2231 - accuracy: 0.9201 - val_loss: 0.3114 - val_accuracy: 0.8878\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=30, validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
